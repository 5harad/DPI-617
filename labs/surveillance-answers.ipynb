{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/5harad/DPI-617/blob/main/labs/surveillance-answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAICDccs5vD2"
      },
      "source": [
        "## **Law, Order, and Algorithms**\n",
        "## Estimating the prevalence and placement of surveillance cameras"
      ],
      "id": "MAICDccs5vD2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting started**\n",
        "\n",
        "Before you start, create a copy of this Jupyter notebook in your own Google Drive by clicking `Copy to Drive` in the menubar. If you do not do this your work will not be saved! \n",
        "\n",
        "Remember to save your work frequently by pressing command-S or clicking File > Save in the menubar. \n",
        "\n",
        "We recommend completing this problem set in Google Chrome."
      ],
      "metadata": {
        "id": "Oh4Rfwrg6P39"
      },
      "id": "Oh4Rfwrg6P39"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing libraries**\n",
        "\n",
        "As before, we'll start by loading the libraries that we'll use in this lab. This time we'll need to install the `ggmap` library first, which lets us visualize some of our geographic results. \n",
        "\n",
        "Run the cell below to install and load the libraries. It may take a minute or two to complete."
      ],
      "metadata": {
        "id": "DWYXS0p-6Ucm"
      },
      "id": "DWYXS0p-6Ucm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lma9PthY5vD3"
      },
      "outputs": [],
      "source": [
        "# install the library ggmap\n",
        "install.packages('ggmap')\n",
        "\n",
        "# load libraries\n",
        "library(tidyverse)\n",
        "library(ggmap)\n",
        "\n",
        "# Set some formatting options\n",
        "options(digits = 3, repr.matrix.max.rows = 10, repr.matrix.max.cols = 100)\n",
        "theme_set(theme_bw())"
      ],
      "id": "Lma9PthY5vD3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5kcWq-d5vD5"
      },
      "source": [
        "## Background\n",
        "\n",
        "In this lab, we'll work to replicate the results from [Sheng et al. (2021)](https://5harad.com/papers/surveilling-surveillance.pdf), where the authors estimate the prevalence of surveillance cameras across the United States using Google street view data.\n",
        "\n",
        "Specifically, we will perform two tasks in this lab:\n",
        "1. Estimate the density of surveillance cameras in San Francisco;\n",
        "2. Examine the relationship between camera placement and the demographic composition of a neighborhood."
      ],
      "id": "G5kcWq-d5vD5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npJXpYEF5vD5"
      },
      "source": [
        "### Data"
      ],
      "id": "npJXpYEF5vD5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to load the data we'll be using in this lab."
      ],
      "metadata": {
        "id": "pcpI1sgS8vvi"
      },
      "id": "pcpI1sgS8vvi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLWPzar85vD5"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "fname = 'https://github.com/5harad/DPI-617/raw/main/data/surveillance_sf.RData?raw=true'\n",
        "load(url(fname))"
      ],
      "id": "JLWPzar85vD5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgLR8bXj5vD6"
      },
      "source": [
        "We are loading four objects into the notebook. They are:\n",
        "\n",
        "#### cameras_sf\n",
        "(one row per image)\n",
        "- `panoid`: ID of image \n",
        "- `lat-lon`: coordinates of image\n",
        "- `period`: year of image\n",
        "- `detected`, `verified`: whether a (verified) camera is in the image, explained below\n",
        "\n",
        "#### census_sf\n",
        "(one row per census block-group)\n",
        "- `GEOID`, `NAME`: ID and name of census block group (CBG)\n",
        "- `total_pop`: total population of CBG\n",
        "- `total_white`: total non-Hispanic white population of CBG\n",
        "- `geometry`: multipolygon shape of census block group\n",
        "\n",
        "#### cameras_all\n",
        "(one row per image, covering 10 U.S. cities)\n",
        "- `panoid`: ID of image \n",
        "- `city`: city of image\n",
        "- `period`: year of image\n",
        "- `verified`: indicator for whether the image contains a verified camera\n",
        "- `zone_type`: the designation of the area (e.g., `Residential` or `Commercial`) \n",
        "- `percentage_minority`: demographic composition of the CBG where the image was taken\n",
        "- census_block_group: the CBG of the image\n",
        "\n",
        "#### ggmap_sf\n",
        "- saved map of San Francisco"
      ],
      "id": "dgLR8bXj5vD6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8YbEAGV5vD6"
      },
      "outputs": [],
      "source": [
        "head(cameras_sf)"
      ],
      "id": "N8YbEAGV5vD6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4084oFZu5vD6"
      },
      "source": [
        "### Object detection models"
      ],
      "id": "4084oFZu5vD6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Z9t3315vD7"
      },
      "source": [
        "In order to identify cameras using street view images, we will use an [object detection](https://en.wikipedia.org/wiki/Object_detection) model.\n",
        "An object detection model is a computer vision model that detects instances of objects of a certain class within an image.\n",
        "In this particular case we are interested in detecting cameras in an image, but in practice such models can be used to detect all kinds of objects.\n",
        "\n",
        "While object detection model performance has increased drastically due in large part to the rise of deep learning, enabling a number of previously impossible applications, they are not perfect models.\n",
        "In order to understand how well the camera detection model works, we evaluate it using two useful metrics: [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall).\n",
        "\n",
        "To define precision and recall, we need to distinguish between model predictions (i.e., whether the model *thinks* an image contains a camera) and the correct answer (i.e., whether an image *actually* contains a camera). The **precision** is the proportion of images that actually contain a camera, among those images where the model believes there is a camera. The **recall** is the proportion of images the model identified as having a camera, among those images that actually contain a camera.\n",
        "\n",
        "In general, given an arbitrary model, we can define precision and recall in terms of model-predicted and actual \"positive\" and \"negative\" cases, terminology that comes from the epidemiology. In our case, a \"positive\" image is one that has a camera, and a \"negative\" image is one that does not. Using this terminology, we can then define the following quantities.\n",
        "\n",
        "* TP: true positives; the number of predicted positive cases that were real positives \n",
        "* TN: true negatives; the number of predicted negative cases that were real negatives \n",
        "* FP: false positives; the number of predicted positives that were actually negative in the data (false alarms, Type I error)\n",
        "* FN: false negatives; the number of predicted negatives that were actually positive in the data (Type II error) \n",
        "\n",
        "Their definitions can be illustrated using the following table:\n",
        "\n",
        "<br>\n",
        "<style type=\"text/css\">\n",
        ".tg  {border-collapse:collapse;border-spacing:0; margin: auto;}\n",
        ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#BBBBBB;}\n",
        ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#BBBBBB;}\n",
        ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
        "</style>\n",
        "<table class=\"tg\">\n",
        "  <tr>\n",
        "    <th class=\"tg-baqh\"></th>\n",
        "    <th class=\"tg-baqh\">Real positive</th>\n",
        "    <th class=\"tg-baqh\">Real negative</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"tg-baqh\"><strong>Predicted positive</strong></td>\n",
        "    <td class=\"tg-baqh\">TP</td>\n",
        "    <td class=\"tg-baqh\">FP</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"tg-baqh\"><strong>Predicted negative</strong></td>\n",
        "    <td class=\"tg-baqh\">FN</td>\n",
        "    <td class=\"tg-baqh\">TN</td>\n",
        "  </tr>\n",
        "</table>\n",
        "<br>\n",
        "\n",
        "\n",
        "Precision is defined as\n",
        "$\\frac{TP}{TP + FP} = \\frac{N_{\\text{correct model-identified cameras}}}{N_{\\text{model-identified cameras}}}$\n",
        "\n",
        "Recall is defined as\n",
        "$\\frac{TP}{TP + FN} = \\frac{N_{\\text{correct model-identified cameras}}}{N_{\\text{real cameras}}}$\n",
        "\n",
        "\n",
        "This diagram from Wikipedia visually illustrates these definitions:\n",
        "\n",
        "<p><a href=\"https://commons.wikimedia.org/wiki/File:Precisionrecall.svg#/media/File:Precisionrecall.svg\"><img width='350px' src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/1200px-Precisionrecall.svg.png\" alt=\"Precisionrecall.svg\"></a><br>\n",
        "By <a href=\"//commons.wikimedia.org/wiki/User:Walber\" title=\"User:Walber\"&>Walber</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=36926283\">Link</a></p>\n"
      ],
      "id": "P_Z9t3315vD7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAYLCymP5vD7"
      },
      "source": [
        "### Exercise: calculate model precision\n",
        "We previously trained a camera detection model, which we then applied to a sample of Google street view images. Afterwards, human annotators reviewed each of the images in which a camera was `detected` by the model and `verified` whether a camera was actually there.\n",
        "Now, as an exercise, let's calculate the precision of our model using the columns `verified` and `detected` from the data frame `cameras_sf`. "
      ],
      "id": "jAYLCymP5vD7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2SqWiDl5vD8"
      },
      "outputs": [],
      "source": [
        "# Your code here!\n",
        "# START solution\n",
        "cameras_sf %>%\n",
        "  filter(detected) %>%\n",
        "  summarize(precision = mean(verified))\n",
        "# END solution"
      ],
      "id": "a2SqWiDl5vD8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1gCS1d35vD8"
      },
      "source": [
        "### Estimating the prevalence of surveillance cameras in San Francisco\n",
        "\n",
        "As we see above, the model's performance is far from perfect.\n",
        "However, we are still able to use this model to help us estimate the number of cameras in SF.\n",
        "\n",
        "By running the camera detection model on a random sample of street view images (in `cameras_sf`), we can estimate the total number of cameras in SF using three ingredients:\n",
        "\n",
        "1. The number of verified cameras in this sample\n",
        "1. The percentage of all roads in SF covered by the sample\n",
        "1. The model's recall"
      ],
      "id": "F1gCS1d35vD8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise: Compute the number of verified cameras in this sample"
      ],
      "metadata": {
        "id": "i-ET23lXMm7R"
      },
      "id": "i-ET23lXMm7R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5oPUA3r5vD8"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of verified cameras\n",
        "# Store the answer in the variable n_verified\n",
        "# Your code here!\n",
        "# START solution\n",
        "n_verified <- sum(cameras_sf$verified)\n",
        "# END solution"
      ],
      "id": "A5oPUA3r5vD8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKejoUGv5vD8"
      },
      "source": [
        "### Exercise: calculate the fraction of roadway in SF covered by the sample\n",
        "\n",
        "There are about 3.1 million meters of road in San Francisco, and an image covers, on average, 24.1 meters. When computing the fraction of roadway covered by the images, keep in mind that every street view image covers only one side of a two-sided street."
      ],
      "id": "NKejoUGv5vD8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "64eDM_6A5vD8"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "# Total road length in San Francisco (in meters)\n",
        "road_length_m <- 3108000\n",
        "# Average length of road covered by one image in the dataset (in meters)\n",
        "avg_image_length_m <- 24.1\n",
        "\n",
        "# Calculate percentage of all roads in SF covered by the sample\n",
        "# Store the answer in the variable frac_road_covered\n",
        "# Your code here!\n",
        "# START solution\n",
        "n_images <- length(cameras_sf$panoid)\n",
        "frac_road_covered <- avg_image_length_m * n_images / (2 * road_length_m)\n",
        "# END solution"
      ],
      "id": "64eDM_6A5vD8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise: Estimating recall\n",
        "\n",
        "Discuss how you would estimate the **recall** of our camera detection model. Is estimating recall easier or harder than estimating precision in our case?"
      ],
      "metadata": {
        "id": "YISgtNxmLppN"
      },
      "id": "YISgtNxmLppN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sheng et al. estimated the camera detection model's recall is 0.67. Now we are able to estimate the total number of cameras in SF visible from the road.\n"
      ],
      "metadata": {
        "id": "ySXJV6bsMMQW"
      },
      "id": "ySXJV6bsMMQW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Dhl3np5vD9"
      },
      "source": [
        "### Exercise: derive a formula to estimate the number of cameras in SF\n",
        "\n",
        "Use the quantities we computed above to estimate the number of cameras in San Francisco.\n",
        "\n",
        "Step 1. Using our estimated `recall`, estimate the actual number of cameras in our *sample* of street-view images.\n",
        "\n",
        "Step 2. Using `frac_road_covered`, estimate the number of cameras in the whole city."
      ],
      "id": "12Dhl3np5vD9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKMw-5bN5vD9"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "# Recall of the camera detection model\n",
        "recall <- 0.67\n",
        "\n",
        "# Estimate camera detections and density\n",
        "# Store the answer in the variable est_cameras\n",
        "# Your code here!\n",
        "# START solution\n",
        "est_cameras_in_sample <- n_verified / recall\n",
        "est_cameras <-  est_cameras_in_sample / frac_road_covered\n",
        "# END solution"
      ],
      "id": "zKMw-5bN5vD9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYzoKSNe5vD9"
      },
      "source": [
        "### Plotting the location of camera detections\n",
        "We can plot the locations of detected cameras in our sample on a map to help us better understand their spatial distribution. What patterns do you notice in the placement of cameras?"
      ],
      "id": "wYzoKSNe5vD9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFo5RMJx5vD9"
      },
      "outputs": [],
      "source": [
        "ggmap(ggmap_sf, extent = \"device\") +\n",
        "  geom_point(data = cameras_sf %>% \n",
        "               filter(verified),\n",
        "             aes(x = lon, y = lat),\n",
        "             position = \"jitter\", \n",
        "             shape = 25, fill = \"white\", color = \"red\",\n",
        "             alpha = 1, size = 1.5) +\n",
        "  theme(axis.text = element_blank(), \n",
        "        axis.title = element_blank(),\n",
        "        axis.ticks = element_blank(),\n",
        "        panel.grid = element_blank(),\n",
        "        panel.border = element_blank())"
      ],
      "id": "IFo5RMJx5vD9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPD_dKrk5vD9"
      },
      "source": [
        "### Racial disparities in camera placement\n",
        "By performing the analysis above for multiple cities across the U.S. and combining the results with census data,\n",
        "we can examine the relationship between camera density and share of minorities (defined as those who identify as either Hispanic or non-white) in that location.\n",
        "\n"
      ],
      "id": "IPD_dKrk5vD9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dn0qt105vD9"
      },
      "outputs": [],
      "source": [
        "cameras_all %>%\n",
        "  ggplot(aes(x = percentage_minority, y = verified)) +\n",
        "  #geom_hline(yintercept = avg_detection_rate, linetype = \"dashed\", color = \"gray\") + # avg detection rate\n",
        "  geom_smooth(method = \"lm\", \n",
        "              formula = y ~ poly(x, degree = 2),\n",
        "              se = T) +\n",
        "  scale_x_continuous(\n",
        "    name = \"Minority share of population (in Census Block Group)\", \n",
        "    #breaks = seq(0, 1, 0.1),\n",
        "    expand = expansion(mult = c(0, 0.05)),\n",
        "    labels = scales::percent_format(accuracy = 1)\n",
        "  ) +\n",
        "  scale_y_continuous(\n",
        "    name = \"Camera identification rate\",  \n",
        "    breaks = seq(0, 0.012, 0.003),\n",
        "    expand = expansion(mult = c(0, 0.1)),\n",
        "    labels = scales::percent_format(accuracy = 0.1)\n",
        "  ) +\n",
        "  theme(\n",
        "    panel.grid = element_blank(),\n",
        "    panel.border = element_blank(),\n",
        "    axis.text = element_text(size = 16, family = \"Helvetica\", color = \"black\"),\n",
        "    axis.title = element_text(size = 16, family = \"Helvetica\", color = \"black\"),\n",
        "    axis.line = element_line(linewidth = 0.5, color = \"black\"),\n",
        "    axis.ticks.x = element_line(linewidth = 0.5, color = \"black\"),\n",
        "    axis.ticks.y = element_line(linewidth = 0.5, color = \"black\")\n",
        "  ) "
      ],
      "id": "9dn0qt105vD9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise: Disparate impacts in camera placement\n",
        "\n",
        "Discuss the plot above. What might be driving the results?"
      ],
      "metadata": {
        "id": "p4nMNymHRMCv"
      },
      "id": "p4nMNymHRMCv"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.3"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}